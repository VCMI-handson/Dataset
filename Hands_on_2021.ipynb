{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hands_on_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VCMI-handson/Dataset/blob/master/Hands_on_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIVm3Qd8Ms4q"
      },
      "source": [
        "# Image Segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHRJWUbtMsrB"
      },
      "source": [
        "![대체 텍스트](https://drive.google.com/uc?export=view&id=1C_0gHRwgYOxWxZfcdzUTbJymACw801s2)\n",
        "\n",
        "[출처](https://medium.com/zylapp/review-of-deep-learning-algorithms-for-object-detection-c1f3d437b852)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7rXugkuL1Fe"
      },
      "source": [
        "# Step 0. 실습환경 셋팅"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bpcPhkPvdV3"
      },
      "source": [
        "##1. Google 계정 로그인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LovHsPLMoa6"
      },
      "source": [
        "##2. 하단 링크 접속\n",
        "\n",
        "##**[https://colab.research.google.com/github/VCMI-handson/210814](https://colab.research.google.com/github/VCMI-handson/210814)**\n",
        "\n",
        "\n",
        "![대체 텍스트](https://drive.google.com/uc?export=view&id=1dzZvu44EMw7LQ7iGJfutXSuaZeK_6VoA)\n",
        "\n",
        "![대체 텍스트](https://drive.google.com/uc?export=view&id=1puX_WuNVBWdsm9qJwulz2uTniUcDYaoE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzYzJG6a30Xx"
      },
      "source": [
        "# Step 1. 데이터셋 불러들이기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIVjUrRO4D1y"
      },
      "source": [
        "##Lung segmentation from Chest X-Ray dataset\n",
        "\n",
        "https://www.kaggle.com/nikhilpandey360/lung-segmentation-from-chest-x-ray-dataset\n",
        "\n",
        "![대체 텍스트](https://drive.google.com/uc?export=view&id=1Oa-iXD9IMQre4Ao7CyslObAtZRBCskvB)\n",
        "![대체 텍스트](https://drive.google.com/uc?export=view&id=1lz6EHChnPtCbkH6XI_Tm0_tEpJWnkb1a)\n",
        "![대체 텍스트](https://drive.google.com/uc?export=view&id=1ZK09wg_gJGGCyKnvkSkgxcpl1Pz4esDa)\n",
        "\n",
        "\n",
        "###Lung_Segmentation.zip\n",
        "###256x256x3\n",
        "###566 datasets [image, label]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Msw9-ZMFhQf"
      },
      "source": [
        "!rm -rf *\n",
        "!wget https://github.com/mi2rl/datasets/raw/master/Lung_Segmentation.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuS9w6XcFtw3"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U547OnoGuh3"
      },
      "source": [
        "!unzip Lung_Segmentation.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDzC0x3y9Vcv"
      },
      "source": [
        "**(DICOM 을 PNG로 바꾸고 싶은 경우)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u62TXs5jFdPK"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH1EpwaV9QdS"
      },
      "source": [
        "!pip install pydicom\n",
        "!pip install pillow\n",
        "!pip install numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yl7PFPP9SC4"
      },
      "source": [
        "import pydicom as dicom\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "dcm_path = \"./Samples/dcm\"\n",
        "data_path = \"./Samples/image\"\n",
        "os.mkdir(data_path)\n",
        "files = os.listdir(dcm_path)\n",
        "\n",
        "for f in files:\n",
        "    image_path = os.path.join(dcm_path, f)\n",
        "\n",
        "    f1 = os.path.splitext(f)[0]\n",
        "    d1 = os.path.join('{}.png'.format(f1))\n",
        "\n",
        "    png_path = os.path.join(data_path, d1)\n",
        "\n",
        "    ds = dicom.dcmread(image_path)\n",
        "\n",
        "    new_image = ds.pixel_array.astype(float)\n",
        "    scaled_image = (np.maximum(new_image, 0) / new_image.max()) * 255.0\n",
        "    scaled_image = np.uint8(scaled_image)\n",
        "    final_image = Image.fromarray(scaled_image)\n",
        "    \n",
        "    final_image.save(png_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qzcvidiFgsj"
      },
      "source": [
        "**Lung Segmentation 데이터 설정하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndHDpKrvGyzP"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "IMG_CHANNELS = 3\n",
        "\n",
        "data_path = \"./Lung_Segmentation\"\n",
        "\n",
        "files = os.listdir(os.path.join(data_path, 'image'))\n",
        "file_headers = []  #python list\n",
        "for f in files:\n",
        "    f1 = os.path.splitext(f)[0]\n",
        "    file_headers.append(f1)\n",
        "#print(file_headers)\n",
        "\n",
        "X_all = np.zeros((len(file_headers), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "y_all = np.zeros((len(file_headers), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.float32)\n",
        "\n",
        "count = 0\n",
        "for fh in file_headers:\n",
        "    f1 = os.path.join(data_path, 'image', '{}.png'.format(fh))\n",
        "    l1 = os.path.join(data_path, 'label', '{}.png'.format(fh))\n",
        "    \n",
        "    img = imread(f1)[:,:,:IMG_CHANNELS]\n",
        "    mask = imread(l1)\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "\n",
        "    X_all[count] = img\n",
        "    y_all[count] = mask\n",
        "    \n",
        "    count += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5PJph8W3h39"
      },
      "source": [
        "**딥러닝을 위한 데이터 전처리**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edXzK3BiIKoB"
      },
      "source": [
        "X_all = X_all.astype('float32') / 255.\n",
        "y_all = y_all.astype('float32') / 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgZM4cCm3kT0"
      },
      "source": [
        "**학습, 검증, 테스트 데이터 셋으로 분리**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAcUzVN3IP1Y"
      },
      "source": [
        "# fix random seed for reproductibility\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2)\n",
        "\n",
        "print('X_train',X_train.shape)\n",
        "print('X_valid',X_valid.shape)\n",
        "print('X_test',X_test.shape)\n",
        "print('y_train',y_train.shape)\n",
        "print('y_valid',y_valid.shape)\n",
        "print('y_test',y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj-8QGAM4uLF"
      },
      "source": [
        "# Step 2. 데이터 살펴보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA3G2uHrIXeF"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plotTrainData(a,b,c):\n",
        "    for i in range(3):\n",
        "        ix = np.random.randint(0, len(a))\n",
        "        plt.subplot(1,2,1)\n",
        "        plt.title(\"X_\" + c)\n",
        "        plt.imshow(a[ix])\n",
        "        plt.axis('off')\n",
        "        plt.subplot(1,2,2)\n",
        "        plt.title(\"y_\" + c)\n",
        "        plt.imshow(np.squeeze(b[ix]), 'gray')\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "        \n",
        "plotTrainData(X_train,y_train, 'train')\n",
        "plotTrainData(X_valid,y_valid, 'valid')\n",
        "plotTrainData(X_test,y_test, 'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoznsNXalnTW"
      },
      "source": [
        "# Step 3. 첫번째 영상분할 모델 (U-Net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfjEcQB9p43M"
      },
      "source": [
        "![대체 텍스트](https://drive.google.com/uc?export=view&id=1vSx_i5kIBjaHTk5pvaa-yOXTX_69UzZh)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNLSqxwzly3S"
      },
      "source": [
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras import backend as keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "\n",
        "def unet(input_size=(256,256,3)):\n",
        "    inputs = Input(input_size)\n",
        "    \n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
        "    conv5 = BatchNormalization()(conv5)\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
        "    conv5 = BatchNormalization()(conv5)\n",
        "    \n",
        "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
        "    conv6 = BatchNormalization()(conv6)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
        "    conv6 = BatchNormalization()(conv6)\n",
        "    \n",
        "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
        "    conv7 = BatchNormalization()(conv7)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
        "    conv7 = BatchNormalization()(conv7)\n",
        "    \n",
        "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
        "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
        "    conv8 = BatchNormalization()(conv8)\n",
        "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
        "    conv8 = BatchNormalization()(conv8)\n",
        "    \n",
        "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
        "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
        "    conv9 = BatchNormalization()(conv9)\n",
        "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
        "    conv9 = BatchNormalization()(conv9)\n",
        "\n",
        "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
        "\n",
        "    return Model(inputs=[inputs], outputs=[conv10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61FPu14nYGLf"
      },
      "source": [
        "**loss 계산**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSCqquL5Ivhs"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljf4PB_al3JX"
      },
      "source": [
        "**생성한 모델 수행**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKk57f5fl244"
      },
      "source": [
        "# build the model\n",
        "model = unet()\n",
        "sgd = tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss=dice_coef_loss, optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "# fix random seed for reproductibility\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "# FIT THE MODEL - OPTIMIZATION\n",
        "hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=20, batch_size=8, verbose=1)\n",
        "model.save('unet.h5')\n",
        "\n",
        "# 학습과정 살펴보기\n",
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "loss_ax.set_ylim([-1.0, -0.0])\n",
        "\n",
        "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
        "acc_ax.set_ylim([0.0, 1.0])\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuray')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pTUUy_Zl8l-"
      },
      "source": [
        "**결과 확인**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfhEZaRjbU4q"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plotPredictions(X_train_, y_train_, X_valid_, y_valid_, X_test_, y_test_, simpleFCN):\n",
        "    model = simpleFCN     \n",
        "\n",
        "    ix = np.random.randint(0, len(X_train_))\n",
        "    input_ = X_train_[ix:ix+1]\n",
        "    mask_ = y_train_[ix:ix+1]\n",
        "    preds_train = model.predict(input_)\n",
        "    preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.title(\"X_train\")\n",
        "    plt.axis('off')\n",
        "    plt.imshow(input_[0])\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.title(\"Y_train\")\n",
        "    plt.axis('off')\n",
        "    plt.imshow(mask_[0][:,:,0], 'gray')\n",
        "    plt.subplot(1,3,3)\n",
        "    ret = model.evaluate(input_, mask_)\n",
        "    plt.title(\"Prediction: %.4f\" % (ret[1]))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(preds_train_t[0][:,:,0], 'gray')\n",
        "    plt.show()\n",
        "    \n",
        "    ix = np.random.randint(0, len(X_valid_))\n",
        "    input_ = X_valid_[ix:ix+1]\n",
        "    mask_ = y_valid_[ix:ix+1]\n",
        "    preds_valid = model.predict(input_)\n",
        "    preds_valid_t = (preds_valid > 0.5).astype(np.uint8)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.title(\"X_valid\")\n",
        "    plt.axis('off')\n",
        "    plt.imshow(input_[0])\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.title(\"Y_valid\")\n",
        "    plt.axis('off')\n",
        "    plt.imshow(mask_[0][:,:,0], 'gray')\n",
        "    plt.subplot(1,3,3)\n",
        "    ret = model.evaluate(input_, mask_)\n",
        "    plt.title(\"Prediction: %.4f\" % (ret[1]))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(preds_valid_t[0][:,:,0], 'gray')\n",
        "    plt.show()\n",
        "    \n",
        "    ix = np.random.randint(0, len(X_test_))\n",
        "    input_ = X_test_[ix:ix+1]\n",
        "    mask_ = y_test_[ix:ix+1]\n",
        "    preds_test = model.predict(input_)\n",
        "    preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.title(\"X_test\")\n",
        "    plt.axis('off')\n",
        "    plt.imshow(input_[0])\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.title(\"Y_test\")\n",
        "    plt.axis('off')\n",
        "    plt.imshow(mask_[0][:,:,0], 'gray')\n",
        "    plt.subplot(1,3,3)\n",
        "    ret = model.evaluate(input_, mask_)\n",
        "    plt.title(\"Prediction: %.4f\" % (ret[1]))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(preds_test_t[0][:,:,0], 'gray')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv_PRoIjl-xj"
      },
      "source": [
        "plotPredictions(X_train, y_train, X_valid, y_valid, X_test, y_test, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RqAkjddevGm"
      },
      "source": [
        "# Step 4. 2번째 영상분할 모델 (Attention U-Net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSGkD__MBktA"
      },
      "source": [
        "![대체 텍스트](https://github.com/lixiaolei1982/Keras-Implementation-of-U-Net-R2U-Net-Attention-U-Net-Attention-R2U-Net.-/blob/master/img/AttU-Net.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kzpb_DGfnuk"
      },
      "source": [
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras import backend as keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "\n",
        "def attention(x, g, n_filters, padding='same', activation='relu'):\n",
        "  original_x = x\n",
        "  x_net = original_x\n",
        "  g_net = g\n",
        "\n",
        "  x_conv = Conv2D(n_filters, (1, 1), activation=None, padding=padding)(x_net)  # contracting_path_results\n",
        "  x_conv = BatchNormalization()(x_conv)\n",
        "  g_conv = Conv2D(n_filters, (1, 1), activation=None, padding=padding)(g_net)  # up_results\n",
        "  g_conv = BatchNormalization()(g_conv)\n",
        "  \n",
        "  net = add([x_conv, g_conv])\n",
        "  net = Activation('relu')(net)\n",
        "  net = Conv2D(1, (1, 1), activation=None, padding=padding)(net)\n",
        "  net = BatchNormalization()(net)\n",
        "  net_a = Activation('sigmoid')(net)\n",
        "  net_result = multiply([original_x, net_a])\n",
        "\n",
        "  return net_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fhlj406ie87O"
      },
      "source": [
        "def Attunet(input_size=(256,256,3)):\n",
        "    inputs = Input(input_size)\n",
        "    \n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
        "    conv5 = BatchNormalization()(conv5)\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
        "    conv5 = BatchNormalization()(conv5)\n",
        "    \n",
        "    up6 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
        "    att6 = attention(conv4, up6, 256)\n",
        "    concat6 = concatenate([up6, att6], axis=3)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(concat6)\n",
        "    conv6 = BatchNormalization()(conv6)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
        "    conv6 = BatchNormalization()(conv6)\n",
        "    \n",
        "    up7 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
        "    att7 = attention(conv3, up7, 128)\n",
        "    concat7 = concatenate([up7, att7], axis=3)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(concat7)\n",
        "    conv7 = BatchNormalization()(conv7)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
        "    conv7 = BatchNormalization()(conv7)\n",
        "    \n",
        "    up8 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
        "    att8 = attention(conv2, up8, 64)\n",
        "    concat8 = concatenate([up8, att8], axis=3)\n",
        "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(concat8)\n",
        "    conv8 = BatchNormalization()(conv8)\n",
        "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
        "    conv8 = BatchNormalization()(conv8)\n",
        "    \n",
        "    up9 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
        "    att9 = attention(conv1, up9, 32)\n",
        "    concat9 = concatenate([up9, att9], axis=3)\n",
        "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(concat9)\n",
        "    conv9 = BatchNormalization()(conv9)\n",
        "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
        "    conv9 = BatchNormalization()(conv9)\n",
        "\n",
        "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
        "\n",
        "    return Model(inputs=[inputs], outputs=[conv10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLoR6b-1TA4d"
      },
      "source": [
        "**생성한 모델 수행**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ8KDI4aAMvj"
      },
      "source": [
        "# build the model\n",
        "model = Attunet()\n",
        "sgd = tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss=dice_coef_loss, optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "# fix random seed for reproductibility\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "# FIT THE MODEL - OPTIMIZATION\n",
        "hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=20, batch_size=8, verbose=1)\n",
        "model.save('Attunet.h5')\n",
        "\n",
        "# 학습과정 살펴보기\n",
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "loss_ax.set_ylim([-1.0, -0.0])\n",
        "\n",
        "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
        "acc_ax.set_ylim([0.0, 1.0])\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuray')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NNIneIxTK2R"
      },
      "source": [
        "**결과 확인**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lc5XaV5ANlc"
      },
      "source": [
        "plotPredictions(X_train, y_train, X_valid, y_valid, X_test, y_test, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Lnj2wcZk35c"
      },
      "source": [
        "# Step 5. 3번째 영상분할 모델 (Recurrent Residual U-Net: R2U-Net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wrk98H9XBX7g"
      },
      "source": [
        "![대체 텍스트](https://github.com/lixiaolei1982/Keras-Implementation-of-U-Net-R2U-Net-Attention-U-Net-Attention-R2U-Net.-/blob/master/img/R2U-Net.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGLsyMi_b9jA"
      },
      "source": [
        "![대체 텍스트](https://drive.google.com/uc?export=view&id=1T0nksBa4Pe64eurM_fTbB26B1H4T9XpO)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkMPiiFek_T2"
      },
      "source": [
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras import backend as keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "\n",
        "def recurrent_block(input_layer, n_filters, padding='same', activation='relu'):\n",
        "    \n",
        "    input_conv = Conv2D(n_filters, (1, 1), activation=None, padding='same')(input_layer)\n",
        "\n",
        "    conv1 = Conv2D(n_filters, (3, 3), padding='same')(input_layer) \n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "\n",
        "    conv2 = Conv2D(n_filters, (3, 3), padding='same')(add([input_conv, conv1])) \n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = Activation('relu')(conv2)\n",
        "    \n",
        "    return conv2\n",
        "\n",
        "\n",
        "def r2_block(input_layer, n_filters):\n",
        "    \n",
        "    r_block = recurrent_block(input_layer, n_filters)\n",
        "    r_block = recurrent_block(r_block, n_filters)\n",
        "\n",
        "    input_conv = Conv2D(n_filters, (1, 1), activation=None, padding='same')(input_layer)\n",
        "    \n",
        "    out_layer = add([r_block, input_conv])\n",
        "\n",
        "    return out_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNVJsaz9ZCkB"
      },
      "source": [
        "def r2unet(input_size=(256,256,3)):\n",
        "    inputs = Input(input_size)\n",
        "    \n",
        "    rrcnn1 = r2_block(inputs, 32)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(rrcnn1)\n",
        "\n",
        "    rrcnn2 = r2_block(pool1, 64)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(rrcnn2)\n",
        "\n",
        "    rrcnn3 = r2_block(pool2, 128)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(rrcnn3)\n",
        "\n",
        "    rrcnn4 = r2_block(pool3, 256)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(rrcnn4)\n",
        "\n",
        "    rrcnn5 = r2_block(pool4, 512)\n",
        "\n",
        "    up6 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(rrcnn5)\n",
        "    concat6 = concatenate([up6, rrcnn4], axis = 3)\n",
        "    rrcnn6 = r2_block(concat6, 256)\n",
        "\n",
        "    up7 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(rrcnn6)\n",
        "    concat7 = concatenate([up7, rrcnn3], axis = 3)\n",
        "    rrcnn7 = r2_block(concat7, 128)\n",
        "\n",
        "    up8 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(rrcnn7)\n",
        "    concat8 = concatenate([up8, rrcnn2], axis = 3)\n",
        "    rrcnn8 = r2_block(concat8, 64)\n",
        "\n",
        "    up9 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(rrcnn8)\n",
        "    concat9 = concatenate([up9, rrcnn1], axis = 3)\n",
        "    rrcnn9 = r2_block(concat9, 32)\n",
        "\n",
        "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(rrcnn9)\n",
        "\n",
        "    return Model(inputs=[inputs], outputs=[conv10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm9MwSw4S_sa"
      },
      "source": [
        "**생성한 모델 수행**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O--Q3ZkDZLCy"
      },
      "source": [
        "# build the model\n",
        "model = r2unet()\n",
        "sgd = tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss=dice_coef_loss, optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "# fix random seed for reproductibility\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "# FIT THE MODEL - OPTIMIZATION\n",
        "hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=20, batch_size=8, verbose=1)\n",
        "model.save('r2unet.h5')\n",
        "\n",
        "# 학습과정 살펴보기\n",
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "loss_ax.set_ylim([-1.0, -0.0])\n",
        "\n",
        "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
        "acc_ax.set_ylim([0.0, 1.0])\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuray')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6DFN1tATJxH"
      },
      "source": [
        "**결과 확인**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7_zjqlroSdh"
      },
      "source": [
        "plotPredictions(X_train, y_train, X_valid, y_valid, X_test, y_test, model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}